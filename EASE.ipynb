{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe0luTjLkYzJ",
        "outputId": "2c594334-54cb-43fb-d02c-eccaafd7b031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easekit\n",
            "  Downloading easekit-1.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easekit) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easekit) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from easekit) (4.53.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from easekit) (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from easekit) (3.9.1)\n",
            "Collecting vaderSentiment (from easekit)\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->easekit) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->easekit) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->easekit) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->easekit) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->easekit) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->easekit) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easekit)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easekit)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easekit)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easekit)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easekit)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easekit)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easekit)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easekit)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easekit)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easekit)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easekit) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easekit) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->easekit) (0.33.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->easekit) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->easekit) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->easekit) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->easekit) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->easekit) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->easekit) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easekit) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->easekit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->easekit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->easekit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->easekit) (2025.7.14)\n",
            "Downloading easekit-1.0.0-py3-none-any.whl (4.3 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, vaderSentiment, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easekit\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easekit-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install easekit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from easekit import compute_empathy_score\n",
        "\n",
        "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721,
          "referenced_widgets": [
            "a58c2d7bca034f7e88159ef432c92224",
            "432bf683a38b4c5f972ee5de530f07ca",
            "1351b44121fd4c308a79fa4547f2ea9f",
            "7b47abae6a204a9ca8728ba4e8cae5aa",
            "c41ecb0fd9534d08a471eb0a4b51504d",
            "70652bf694834eef9b8d78a8a3aadf6d",
            "fe7f76e9b040472e8c0b1f734a2593a7",
            "735b990810594098b50345402bfb2c13",
            "30bff953bed946aca4e21d8b076c2f4f",
            "977ca1fa4db2452885fd4385edc1023d",
            "dde4cfeca05f4a54a318b7165ddadb0c",
            "3b61858a7aa14496ba9ad2fa7e0151dc",
            "cf43b88710694ffa9d2fd5f8cd255837",
            "abd31ab6cd1b4731b9175186f3d360db",
            "ccdb393500f6405b9aa08917e6fac50c",
            "86650c2fc5c64749b59103c06ea5892d",
            "bf72806b7173445f84d68bdfc5601883",
            "9038b11dc05445ad9688b8f6f47cd9e3",
            "78097e422ac44ee29e1feaae66ac8935",
            "851303c6920b446c813f2760685972f6",
            "920f47b029d14e3884e2b6b0b568ae47",
            "8d805c7a64d9473793c9c6efca016e39",
            "7fa06498b06e45e7812369de51ec9b6d",
            "72b3a291ca134ef9b6451fe1372efb48",
            "f63634c85075493fba159f380dc069ee",
            "43d01ca7fc3a4aac9842431aec490889",
            "056ddfb88b9248e3a9c884fe0fa5ca88",
            "67b9053929fd45d18f0e00160d686a2b",
            "365e37c01cb046dabcd481c524271a78",
            "7e82643c600d4b41abe0b00a78e3ff26",
            "b29dabfe5bb64449a1b3ba4f1a7bf6f1",
            "715847697072432db64d98df570d7799",
            "43901c04d471420caf38b1904e10ef2a",
            "7a777257866e41c9ade73eb711aa6f5a",
            "802001bd5e354e0fa93a86f038c8d73e",
            "6267c049333b4ece86b5bfaa06bff7a5",
            "e787f5a7f0c348bca3d9c3a151bf7dad",
            "1cad8728b6ab450b9bd2039fed6c8b11",
            "545db5a278b342d2adedd57159e23129",
            "492c48b1eeba4a72bc78126fe15f0957",
            "5e01f2fd34a74a608a4567e8e37c1cc4",
            "768509c79f774a0fb5da8b9265fc9e5d",
            "83bfe27cdd2f41dc8c9bf4470d8baed5",
            "8ce4b6f6ec6049109bc0ccfebab09b3a",
            "503fc0da9c6e4e29a07622b48ab8272d",
            "370c994b617f49d48c7c307ac86958df",
            "768cc36771e24434a5b562722184cf23",
            "db94149530a5421cadeff4499fc58bf0",
            "0afe7a554fc14bcebe04843bc8564a6c",
            "98a8fafb17b947d5b87220c6a630c61d",
            "b56f5332724844f6a7f84cf050924f15",
            "38f13b0f2c1a4f0c8ae3828689b54545",
            "0e556d6746414910ab33079f6139e829",
            "b0940ee9f4da45c6895c346acaf6e2b8",
            "f5aeb7027fb94587807d26100c1689e8",
            "be7fa804d55648f28d60b7ac72aaddfe",
            "9351bb53637941b086e42da7acdb5efa",
            "fd85584ddf2b49608ae24e183b1b5d3a",
            "f1d47d81ed2c4b42ba1102f69e11aefd",
            "084b91c9fb5141dc9606a22ece6d0508",
            "ffdf25f2f2784d12a1ac7007836a6c58",
            "259cb68ac1404fb1a55536c468ca402d",
            "6c4a06d77aeb4de198fb3cec8b132737",
            "352a2a273085492ba0406cd9d333906e",
            "3a30015fe9ef4d249dfe2e71c7a85212",
            "d4738060c8af4219a408ce93678af14a",
            "9ab499efd00f47fbbbbbbad839aedc7d",
            "f69cf3a4d48b4ae4ad94cac7d2475539",
            "f9930040f890408ca8f998d8bcc0158b",
            "9b3cb928b32f4131b4fd2bfa9a6220e3",
            "6ca5e67a94514ed4b5ec1d6f7ed0e85d",
            "d5847690fe2745d8a5383245cd7876cf",
            "78346910b70943ad8f62422c8b9219f2",
            "3bed83da0bd44d1e8190a9763f3b8b00",
            "4cfb1bb88be74d40abb75efc9fe6d8ee",
            "24741f04ca494e7bae30d4b4e200f8e8",
            "b3f529b539a44c1687dcd2cf593d9e98",
            "4b97bf8c7c994b4e81da003db03b5e7a",
            "f6a6bebf0c004320b9b25049ea201cb0",
            "65ac69ae56d746fca528c5f70de55839",
            "4ae1c34f77e44c4d8b1bc44eaa20e148",
            "0dd6fcbe090545048a118de0f4b5b8a6",
            "5138b5cde44e459cabf52e94653ca5e6",
            "9410cb55df5a483284b960e5acc06d6c",
            "cbfccca470434909a0537960fc426bc5",
            "dba944ef6b4d43db980fdc4ae87346f1",
            "8bf3bdf1f5534226a2bf55177f557a73",
            "5a146afb34bd4357b5bacf2e7d597449",
            "1c5a49b74f354800805863e482d2e2ec",
            "92edfe085fea412095b6246c932154cf",
            "db3f87c7fd9e48358d6cf77765082d35",
            "0af42418fe524b74b29d5b5595700928",
            "d906b19d3b1b47dc95c3168775bef865",
            "b0491892221b47f88a2a3ec2da366181",
            "9a38953905a9428d84eb639ae3df083a",
            "c73da2c8237947229e452e9cd96ece5c",
            "f01fecc5b7ee432d8b58ff901471d72b",
            "2bae29fd2c624f0484c7aa75f990b639",
            "3f3a67ba24664c349ba03d4210bef442",
            "17425d44bf814d9abc0e0de9a94f9b2b",
            "ea62baa5f9ce4a299ba2c48146b30631",
            "6124cc94153445e1875869b16a9c6b0c",
            "8061ed4cfaf24bf3a82d6d06d41c095b",
            "492fb0feba6b4f2dbd56da27f719d133",
            "080c105eddbe48f38e378cc1da43dc05",
            "7aeca8ca1bd54526a796cd24b066873c",
            "262a83cb43a243fd90bd09ba64e259be",
            "ef05f79ea19846d4b32ff9d3f3ca54f1",
            "896e5a656a2c4549b8c7a89a7fb12d25",
            "3b76a526dc6c41bba529e2d97c07b280"
          ]
        },
        "id": "2Jno75HssMTG",
        "outputId": "76241010-f92e-4af9-99ff-9b0207638aaf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a58c2d7bca034f7e88159ef432c92224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b61858a7aa14496ba9ad2fa7e0151dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fa06498b06e45e7812369de51ec9b6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a777257866e41c9ade73eb711aa6f5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "503fc0da9c6e4e29a07622b48ab8272d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be7fa804d55648f28d60b7ac72aaddfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ab499efd00f47fbbbbbbad839aedc7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b97bf8c7c994b4e81da003db03b5e7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c5a49b74f354800805863e482d2e2ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17425d44bf814d9abc0e0de9a94f9b2b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: In order to implement the metric on any other language, please replace the model_name with your desired model to obtain sentence embeddings"
      ],
      "metadata": {
        "id": "pb7kecsfsR2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"I am very upset\"\n",
        "response = \"Why?\"\n",
        "reference = \"Why? What happened?\"\n",
        "\n",
        "result = compute_empathy_score(context, response, reference, model, tokenizer)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3q4F0gjr2b9",
        "outputId": "b25038ba-c95a-4d15-f3c6-28eac265a5f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'relevance_score': np.float32(0.69147503), 'sentiment_score': 1.0, 'overlap_score': 0.0, 'empathy_score': np.float32(0.563825)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"I am very upset\"\n",
        "response = \"Why would be upset about anything?\"\n",
        "reference = \"Why? What happened?\"\n",
        "\n",
        "result = compute_empathy_score(context, response, reference, model, tokenizer)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK8TvhyYr_qb",
        "outputId": "1a6f3a4f-518a-4415-eaff-403b24563707"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'relevance_score': np.float32(0.5329364), 'sentiment_score': -0.6696807405948639, 'overlap_score': 0.16666666666666666, 'empathy_score': np.float32(0.009974117)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For a different language, say Hindi:"
      ],
      "metadata": {
        "id": "5WlrvdzCtNc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "29652348668d4452b62584ec7262f3ab",
            "702986ab2dcc4b018ae6899e15f8d88c",
            "904bd79262364b2fa5b7a81d1f464e3e",
            "44e2e1803e1b41429dcbc3592a6b33a9",
            "34161203211a431e9d2aa02ff6169eb2",
            "90ddb82667cb4e3ea9aabcb0401eab58",
            "526f01612074472199b04e3ebcb5431a",
            "3882c56143464065a42c8f19ace3c2cd",
            "76dd0c6778344851930a23cd5b0a09bd",
            "ca4e10f30a8d4892b08c5766dfb48405",
            "d9fd15e88e4a40d1bcea73dd0ef7f8dc",
            "a690d712772a43be9055faca8f57d2fb",
            "c005a0363c0749229640d5e8eb3268d4",
            "ebd8026a813d4947b076d4f753d07396",
            "2b736ee19c8c4d96a15012e5078003be",
            "37613370521645e289a82bb169c47e68",
            "b92217c842964414a7b4618c9ab033f3",
            "beafa72c5df2484786f2bd1a769a68cb",
            "eb89d7808114408dbc6b1d0f41a5f34c",
            "f0b8388396f1455fa0aff2255d3d0845",
            "9388d3a91b74456682def714418babdc",
            "ada283b440014988a817bd929c70e5e2",
            "169128556ef248fd9ca3d8759cb6320b",
            "c6d54253aa9a4b598df1f6c64958a4fd",
            "6845e4ce9a3545f0aef89048fcbef0f8",
            "a8510b3bb6a34b5880033e6c51db5b5b",
            "200c9dc59280451ba3a83c588df699d2",
            "0e13ed43ba2a4bfda8a73fed2e439b89",
            "12b350f6fc764646ad27137ccfde05de",
            "ed669ba486184a01a00ed8e578f97eb0",
            "f9ed0fb40c454988966b38cb8112db9b",
            "c869f3d4e7b1443cbba258eece6c24f1",
            "16c3038d549d48569e36dfe890f1c5af",
            "7af2ca610d5f43dcb81a1fde0efde447",
            "9b201ff4a1fb4280971fdfe6d9fcead0",
            "a815457ea5ac453bbdd31cae373fdc44",
            "08c88f4adc31446b8ab100475c17faba",
            "e9b56171ffe0431ea1164b92941ab4a8",
            "fe0266bfcdd94ca2bcebbbb37f3021c9",
            "9d782adfbe284b088e4a34fe2437a3c9",
            "5b671f7d034048e4b1a343e216a816d5",
            "426267c5d9cb4fa08b3a2763bb4303fa",
            "d0d0cfc7d27f46629ea595979d4cfc9e",
            "f80178b29ab4499d8bf34d132ddd813f",
            "43a8d23d33fb4bb591b15d5541ea4697",
            "6785e0392d4a4256ac22a76c2c9f6eb2",
            "dc9d58ad0f50470f9d41ee568460b935",
            "c44b01da156f4fd68b5e8da1670c701a",
            "a506e8bc4558444d8907b3494c0c3b81",
            "5879c74da9a749c292809a3ff58de5b5",
            "a638ad225dd74c1e8fa7618171955051",
            "c4170bf7794b4fb5b4a6c98a4a62fa24",
            "88a07f3a815c4b86861bb449c9c3c6a1",
            "b5dbce26d25843f1ae1c39a4400ffba3",
            "b402346a90fe415b96b1d35a2083942e"
          ]
        },
        "id": "4ysHHwgxtSTr",
        "outputId": "7d41ed9b-3e2f-443b-9da6-8ef0cfa27f19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29652348668d4452b62584ec7262f3ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a690d712772a43be9055faca8f57d2fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "169128556ef248fd9ca3d8759cb6320b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7af2ca610d5f43dcb81a1fde0efde447"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43a8d23d33fb4bb591b15d5541ea4697"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"मैंने अभी-अभी एक दुर्घटना में अपना दोस्त खो दिया|\" #I just lost my friend in an accident.\n",
        "reference = \"मुझे आपके दोस्त के बारे में सुनकर बहुत दुख हुआ|\" #I'm so sorry to hear about your friend.\n",
        "response = \"मुझे आपके दोस्त के बारे में दुख है\" #I'm sorry about your friend\n",
        "\n",
        "result = compute_empathy_score(context, response, reference, model, tokenizer)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QIpfTo8tYJR",
        "outputId": "76be2f63-9551-4d04-f61d-792ef3738275"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'relevance_score': np.float32(0.90173376), 'sentiment_score': 1.0, 'overlap_score': 0.25, 'empathy_score': np.float32(0.7172446)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please try more such examples."
      ],
      "metadata": {
        "id": "WOc3P52ns3RT"
      }
    }
  ]
}
